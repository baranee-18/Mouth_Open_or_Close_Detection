{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened 120\n",
      "Closed 150\n",
      "Closed 180\n",
      "Opened 210\n",
      "Opened 240\n",
      "Opened 270\n",
      "Opened 300\n",
      "Opened 330\n",
      "Opened 360\n",
      "Closed 390\n",
      "Closed 420\n",
      "Closed 450\n",
      "Closed 480\n",
      "Closed 510\n",
      "Opened 540\n",
      "Opened 600\n",
      "Opened 630\n",
      "Opened 660\n",
      "Opened 690\n",
      "Closed 720\n",
      "Closed 750\n",
      "Opened 780\n",
      "Opened 810\n",
      "Opened 840\n",
      "Opened 870\n",
      "Opened 900\n",
      "Closed 930\n",
      "Closed 960\n",
      "Closed 990\n",
      "Closed 1020\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Detect a face in webcam video and check if mouth is open.\n",
    "\"\"\"\n",
    "import face_recognition\n",
    "import cv2\n",
    "from mouth_open_algorithm import get_lip_height, get_mouth_height\n",
    "from datetime import datetime\n",
    "\n",
    "def is_mouth_open(face_landmarks):\n",
    "    top_lip = face_landmarks['top_lip']\n",
    "    bottom_lip = face_landmarks['bottom_lip']\n",
    "\n",
    "    top_lip_height = get_lip_height(top_lip)\n",
    "    bottom_lip_height = get_lip_height(bottom_lip)\n",
    "    mouth_height = get_mouth_height(top_lip, bottom_lip)\n",
    "    \n",
    "    # if mouth is open more than lip height * ratio, return true.\n",
    "    ratio = 0.5\n",
    "#     print('top_lip_height: %.2f, bottom_lip_height: %.2f, mouth_height: %.2f, min*ratio: %.2f' \n",
    "#           % (top_lip_height,bottom_lip_height,mouth_height, min(top_lip_height, bottom_lip_height) * ratio))\n",
    "          \n",
    "    if mouth_height > min(top_lip_height, bottom_lip_height) * ratio:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "# Get a reference to webcam #0 (the default one)\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object to save video to local\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') # codec\n",
    "# cv2.VideoWriter( filename, fourcc, fps, frameSize )\n",
    "#out = cv2.VideoWriter('output.avi', fourcc, 7, (640, 480)) \n",
    "\n",
    "# Load a sample picture and learn how to recognize it.\n",
    "peter_image = face_recognition.load_image_file(\"baranee.jpg\") # replace peter.jpg with your own image !!\n",
    "peter_face_encoding = face_recognition.face_encodings(peter_image)[0]\n",
    "count=0\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "    \n",
    "    if ret:\n",
    "        #cv2.imwrite('frame{:d}.jpg'.format(count), frame)\n",
    "        count += 30 # i.e. at 30 fps, this advances one second\n",
    "        video_capture.set(1, count)\n",
    "    else:\n",
    "        video_capture.release()\n",
    "        break\n",
    "        \n",
    "    # Find all the faces and face enqcodings in the frame of video\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(frame)\n",
    "\n",
    "    # Loop through each face in this frame of video\n",
    "    for (top, right, bottom, left), face_encoding, face_landmarks in zip(face_locations, face_encodings, face_landmarks_list):\n",
    "\n",
    "        #  See if the face is a match for the known face(s)\n",
    "#         match = face_recognition.compare_faces([peter_face_encoding], face_encoding)\n",
    "\n",
    "        name = \"Unknown\"\n",
    "        if match[0]:\n",
    "            name = \"Baranee\"\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom), (right, bottom + 35), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom + 25), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "\n",
    "        # Display text for mouth open / close\n",
    "        ret_mouth_open = is_mouth_open(face_landmarks)\n",
    "        if ret_mouth_open is True:\n",
    "            text = 'Opened'\n",
    "            print(\"Opened {}\".format(count))\n",
    "        else:\n",
    "            text = 'Closed'\n",
    "            print(\"Closed {}\".format(count))\n",
    "        cv2.putText(frame, text, (left, top - 50), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "#    out.write(frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
